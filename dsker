#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Sun Jul  8 21:52:31 2018

@author: mshokry
using Keras

"""


##Model 2
from keras.models import Sequential
from sklearn.preprocessing import StandardScaler
from keras.layers.core import Activation, Dropout, Dense
from keras.wrappers.scikit_learn import KerasClassifier
from sklearn.model_selection import cross_val_score, StratifiedKFold
from sklearn.model_selection import train_test_split
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import classification_report,confusion_matrix,log_loss

import pandas as pd
import numpy as np

data = pd.read_csv('train.csv')

X = data.iloc[:,1:5].values
y = data.iloc[:,5].values

data_t = pd.read_csv('test.csv')
X_index = data_t.iloc[:,0].values
X_T = data_t.iloc[:,1:5].values

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=0)
 

encoder = LabelEncoder()
encoder.fit(y_train)
encoded_Y = encoder.transform(y_train)
def create_larger():
	# create model
	model = Sequential()
	model.add(Dense(60, input_dim=4, kernel_initializer='normal', activation='relu'))
	model.add(Dense(30, kernel_initializer='normal', activation='relu'))
	model.add(Dense(1, kernel_initializer='normal', activation='sigmoid'))
	# Compile model
	model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])
	return model
estimators = []
mod = KerasClassifier(build_fn=create_larger, epochs=20, batch_size=5, verbose=1)
estimators.append(('standardize', StandardScaler()))
estimators.append(('mlp', mod))
pipeline = Pipeline(estimators)
kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=0)
results = cross_val_score(pipeline, X_train, encoded_Y, cv=kfold)
print("Larger: %.2f%% (%.2f%%)" % (results.mean()*100, results.std()*100))

#proba = model.predict(X_test)
#proba = model.predict_proba(X_test)
#model.evaluate(X_test,y_test)

proba = mod.predict_proba(X_test)
y_hat =mod.predict_classes(X_test)
mod.evaluate(X_test,y_test)

log_loss(y_test, proba[:,0])

print(log_loss(y_test,proba[:,0]))
conv = pd.DataFrame(confusion_matrix(y_test,y_hat))
print(conv)
print(classification_report(y_test,y_hat))

p2 = mod.predict_proba(X_T)
submit = np.stack((X_index,p2[:,0]),axis=1)
np.savetxt("submitker.csv", submit, delimiter=",", comments='',header=',Made Donation in March 2007')